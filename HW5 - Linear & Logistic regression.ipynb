{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2019: Homework 05\n",
    "\n",
    "### Linear regression & Logistic regression\n",
    "\n",
    "\n",
    "\n",
    "## Name: Derek Topper\n",
    "\n",
    "## S.I.D.: 2 6 8 6 1 6 7 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises on prediction using sklearn. \n",
    "\n",
    "REMEMBER TO DISPLAY ALL OUTPUTS. If the question asks you to do something, make sure to print your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data:\n",
    "__Data Source__:\n",
    "Data file is uploaded to bCourses and is named: __Energy.csv__ \n",
    "(Link in the Assignment details page on Bcourses) \n",
    "\n",
    "The dataset was created by Angeliki Xifara ( Civil/Structural Engineer) and was processed by Athanasios Tsanas, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).\n",
    "\n",
    "__Data Description__:\n",
    "\n",
    "The dataset contains eight attributes of a building (or features, denoted by X1...X8) and response being the heating load on the building, y1. \n",
    "\n",
    "* X1\tRelative Compactness \n",
    "* X2\tSurface Area \n",
    "* X3\tWall Area \n",
    "*  X4\tRoof Area \n",
    "*  X5\tOverall Height \n",
    "* X6\tOrientation \n",
    "*  X7\tGlazing Area \n",
    "*  X8\tGlazing Area Distribution \n",
    "*  y1\tHeating Load \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.1\n",
    "Read the data file from the csv.\n",
    "\n",
    "Print the count of NaN values for each attribute in the dataset.\n",
    "\n",
    "Print the Range (min, max) and percentiles (25th, 50th, and 75th) of each attribute in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values.\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"Energy.csv\")\n",
    "dATAnulled = data.isnull().any().any()\n",
    "\n",
    "if(dATAnulled==False):\n",
    "    print(\"There are no NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.00000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.00000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764167</td>\n",
       "      <td>671.708333</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>176.604167</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>2.81250</td>\n",
       "      <td>22.307201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.105777</td>\n",
       "      <td>88.086116</td>\n",
       "      <td>43.626481</td>\n",
       "      <td>45.165950</td>\n",
       "      <td>1.75114</td>\n",
       "      <td>1.118763</td>\n",
       "      <td>0.133221</td>\n",
       "      <td>1.55096</td>\n",
       "      <td>10.090196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>514.500000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>110.250000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.682500</td>\n",
       "      <td>606.375000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>140.875000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.75000</td>\n",
       "      <td>12.992500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>673.750000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>183.750000</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>18.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>741.125000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>31.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>808.500000</td>\n",
       "      <td>416.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>43.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1          X2          X3          X4         X5          X6  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.00000  768.000000   \n",
       "mean     0.764167  671.708333  318.500000  176.604167    5.25000    3.500000   \n",
       "std      0.105777   88.086116   43.626481   45.165950    1.75114    1.118763   \n",
       "min      0.620000  514.500000  245.000000  110.250000    3.50000    2.000000   \n",
       "25%      0.682500  606.375000  294.000000  140.875000    3.50000    2.750000   \n",
       "50%      0.750000  673.750000  318.500000  183.750000    5.25000    3.500000   \n",
       "75%      0.830000  741.125000  343.000000  220.500000    7.00000    4.250000   \n",
       "max      0.980000  808.500000  416.500000  220.500000    7.00000    5.000000   \n",
       "\n",
       "               X7         X8          Y1  \n",
       "count  768.000000  768.00000  768.000000  \n",
       "mean     0.234375    2.81250   22.307201  \n",
       "std      0.133221    1.55096   10.090196  \n",
       "min      0.000000    0.00000    6.010000  \n",
       "25%      0.100000    1.75000   12.992500  \n",
       "50%      0.250000    3.00000   18.950000  \n",
       "75%      0.400000    4.00000   31.667500  \n",
       "max      0.400000    5.00000   43.100000  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __REGRESSION__:\n",
    "\n",
    "Using the data, we want to predict \"Heating load\". The output variable is continuous. Hence, we need to use a regression algorithm.  \n",
    "\n",
    "__Q 1.2:__ \n",
    "\n",
    "Split the dataset randomly into train and test. Train a **Linear Regression** model on 80% of the data (80-20 split).\n",
    "What is the intercept and coefficient values?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = 88.70159433067047\n",
      "\n",
      "Coeff is: -68.37080267750885\n",
      "Coeff is: 225622991905.38596\n",
      "Coeff is: -225622991905.41858\n",
      "Coeff is: -451245983810.95044\n",
      "Coeff is: 4.314645528793335\n",
      "Coeff is: -0.09793332568369806\n",
      "Coeff is: 20.400210273917764\n",
      "Coeff is: 0.242865189909935\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "import random\n",
    "\n",
    "LinearRegressionModel= linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "n = int(0.8*len(data.index))\n",
    "train = random.sample(list(data.index),n)\n",
    "\n",
    "\n",
    "X = data.iloc[train,:-1].values\n",
    "y = data.iloc[train,-1].values\n",
    "LinearRegressionModel.fit(X, y)\n",
    "\n",
    "print(\"intercept =\", LinearRegressionModel.intercept_)\n",
    "print(\"\")\n",
    "for each in LinearRegressionModel.coef_:\n",
    "    print(\"Coeff is:\", float(each))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "#### Q.1.3: \n",
    "\n",
    "Create a function which takes arrays of prediction and actual values of the output as parameters to calculate **'Root Mean Square error'** (RMSE) metric:  \n",
    "\n",
    "1. Use the function to calculate the training RMSE  \n",
    "2. Use the function to calculate the test RMSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training RMSE =  2.876500071828896\n",
      "test RMSE =  3.1037185375132577\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "z = LinearRegressionModel.predict(X)\n",
    "#print(len(y))\n",
    "\n",
    "trainRMSE = np.sqrt(np.mean((z - y) ** 2))\n",
    "\n",
    "test = data.drop(train)\n",
    "X_1 = test.iloc[:,:-1].values\n",
    "y_1 = test.iloc[:,-1].values\n",
    "tested = LinearRegressionModel.predict(X_1)\n",
    "testRMSE = np.sqrt(np.mean((tested - y_1) ** 2))\n",
    "\n",
    "print(\"training RMSE = \", (trainRMSE))\n",
    "print(\"test RMSE = \", (testRMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Q1.4: \n",
    "\n",
    "Let's see the effect of amount of data on the performance of prediction model. Use varying amounts of data (100,200,300,400,500,all) from the training data you used previously to train different regression models. Report  training error and test error in each case. Test data  is the same as above for  all  these cases.\n",
    "\n",
    "**Plot error rates vs number of training examples.** Both the training error and the test error should be plotted. Comment on the relationship you observe between the amount of data used to train the model and the test accuracy of the model.\n",
    "\n",
    "__Hint:__ Use array indexing to choose varying data amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Training Error</th>\n",
       "      <th>Validation Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2.821028</td>\n",
       "      <td>3.152501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>2.789586</td>\n",
       "      <td>3.175833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>3.122711</td>\n",
       "      <td>3.301360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>2.841121</td>\n",
       "      <td>3.145272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>2.917720</td>\n",
       "      <td>3.168452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>614</td>\n",
       "      <td>2.864346</td>\n",
       "      <td>3.082191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number  Training Error  Validation Error\n",
       "0     100        2.821028          3.152501\n",
       "1     200        2.789586          3.175833\n",
       "2     300        3.122711          3.301360\n",
       "3     400        2.841121          3.145272\n",
       "4     500        2.917720          3.168452\n",
       "5     614        2.864346          3.082191"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "total = set(train)\n",
    "number = np.array([100,200,300,400,500,len(train)])\n",
    "train_error = np.zeros(6)\n",
    "test_error = np.zeros(6)\n",
    "for i,num in enumerate(number):\n",
    "    \n",
    "    training = sorted(random.sample(total,num))\n",
    "    x = data.iloc[training,:-1].values\n",
    "    y = data.iloc[training,-1].values\n",
    "    \n",
    "    LinearRegressionModel.fit(x, y)\n",
    "    \n",
    "    z = LinearRegressionModel.predict(x)\n",
    "    z_1 = LinearRegressionModel.predict(X_1)\n",
    "    train_error[i] = np.sqrt(np.mean((z - y) ** 2))\n",
    "    test_error[i] = np.sqrt(np.mean((z_1 - y_1) ** 2))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(number, train_error, color='purple',label='training error')\n",
    "ax.plot(number, test_error, color='orange',label='validation error')\n",
    "ax.legend()\n",
    "ax.set_xlabel('size of training data')\n",
    "ax.set_ylabel('error rates')\n",
    "plt.title(\"Error Rates vs Size of Training Data\")\n",
    "\n",
    "d = {'Number': number, 'Training Error':  train_error, \n",
    "                     'Validation Error':  test_error}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** From the plot above, the validation error seems to increase as the amount of training error increases. They also both tend to decrease as the number of training data increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__CLASSIFICATION__:\n",
    "LABELS ARE DISCRETE VALUES.\n",
    "\n",
    "Here the model is trained to classify each instance into a set of predefined discrete classes. On inputting a feature vector into the model, the trained model is able to predict a class of that instance.\n",
    "\n",
    "\n",
    "#### Q2.1\n",
    "Bucket the values of 'y1' i.e 'Heating Load'  from the original dataset into 3 classes:\n",
    "\n",
    "0: 'Low' ( < 14),   \n",
    "1: 'Medium'  (14-28),   \n",
    "2: 'High'  (>28)\n",
    "\n",
    "**HINT:** Use pandas.cut\n",
    "\n",
    "This converts the given dataset  into a classification problem. Use this dataset with transformed 'heating load' to create a **logistic regression** classifiction model that predicts heating load type of a building. Split the data randomly into training and test set. Train the model on 80% of the data (80-20 split).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "bins = pd.IntervalIndex.from_tuples([(0,14),(14,28),(28,50)])\n",
    "cut = pd.cut(data['Y1'],bins,right=False).astype(str)#.map({})\n",
    "\n",
    "cut = cut.map({'(0, 14]':\"Low\",'(14, 28]':'Medium','(28, 50]':'High'})\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.iloc[:,:-2],cut,\n",
    "                                        test_size = 0.2, random_state=100)\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.2 \n",
    "- Print the training and test accuracies\n",
    "- Print the confusion matrix\n",
    "- Print the precision and recall numbers for all the classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8371335504885994\n",
      "testing accuracy:  0.8376623376623377\n",
      "\n",
      "Confusion matrix of test data is: \n",
      "           Predicted 0  Predicted 1  Predicted 2\n",
      "Actual 0           38            5            0\n",
      "Actual 1            2           37           17\n",
      "Actual 2            0            1           54\n",
      "Confusion matrix of train data is: \n",
      "           Predicted 0  Predicted 1  Predicted 2\n",
      "Actual 0          157           18            0\n",
      "Actual 1           29          132           50\n",
      "Actual 2            0            3          225\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92        43\n",
      "           1       0.86      0.66      0.75        56\n",
      "           2       0.76      0.98      0.86        55\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       154\n",
      "   macro avg       0.86      0.84      0.84       154\n",
      "weighted avg       0.85      0.84      0.83       154\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       175\n",
      "           1       0.86      0.63      0.73       211\n",
      "           2       0.82      0.99      0.89       228\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       614\n",
      "   macro avg       0.84      0.84      0.83       614\n",
      "weighted avg       0.84      0.84      0.83       614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "training_accuracy=LogisticRegressionModel.score(x_train,y_train)\n",
    "print ('training accuracy:',training_accuracy)\n",
    "test_accuracy=LogisticRegressionModel.score(x_test,y_test)\n",
    "print('testing accuracy: ',test_accuracy)\n",
    "print(\"\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = LogisticRegressionModel.predict(x_test)\n",
    "ConfusionMatrix=pd.DataFrame(confusion_matrix(y_true, y_pred),\n",
    "            columns=['Predicted 0','Predicted 1','Predicted 2'],\n",
    "                    index=['Actual 0','Actual 1','Actual 2'])\n",
    "print ('Confusion matrix of test data is: \\n',ConfusionMatrix)\n",
    "\n",
    "y_t1 = y_train\n",
    "y_pred1 = LogisticRegressionModel.predict(x_train)\n",
    "ConfusionMatrix=pd.DataFrame(confusion_matrix(y_t1, y_pred1),\n",
    "            columns=['Predicted 0','Predicted 1','Predicted 2'],\n",
    "                    index=['Actual 0','Actual 1','Actual 2'])\n",
    "print ('Confusion matrix of train data is: \\n',ConfusionMatrix)\n",
    "\n",
    "\n",
    "print (\"\")\n",
    "# prec0 = (ConfusionMatrix['Predicted 0'][0] / \n",
    "#          (ConfusionMatrix['Predicted 0'][0] +\n",
    "#           ConfusionMatrix['Predicted 0'][1]))\n",
    "    \n",
    "# prec1 = (ConfusionMatrix['Predicted 1'][1] / \n",
    "#          (ConfusionMatrix['Predicted 1'][0] +\n",
    "#           ConfusionMatrix['Predicted 1'][1]))\n",
    "\n",
    "# prec2 = (ConfusionMatrix['Predicted 2'][2] / \n",
    "#          (ConfusionMatrix['Predicted 2'][2] +\n",
    "#           ConfusionMatrix['Predicted 2'][1]))\n",
    "\n",
    "# rec0 = (ConfusionMatrix['Predicted 0'][0] / \n",
    "#         (ConfusionMatrix['Predicted 0'][0] +\n",
    "#          ConfusionMatrix['Predicted 1'][0]))\n",
    "    \n",
    "# rec1 = (ConfusionMatrix['Predicted 1'][1] / \n",
    "#         (ConfusionMatrix['Predicted 0'][1] + \n",
    "#          ConfusionMatrix['Predicted 1'][1] +\n",
    "#          ConfusionMatrix['Predicted 2'][1]))\n",
    "\n",
    "# rec2 =  (ConfusionMatrix['Predicted 2'][2] / \n",
    "#          (ConfusionMatrix['Predicted 2'][2] + \n",
    "#           ConfusionMatrix['Predicted 1'][2]))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(classification_report(y_t1, y_pred1))\n",
    "\n",
    "#print(\"Precision 0: \", prec0, \" Recall 0: \", rec0)\n",
    "##print(\"Precision 1: \", prec1, \" Recall 1: \", rec1)\n",
    "###print(\"Precision 2: \", prec2, \" Recall 2: \", rec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.3\n",
    "##### K Fold Cross Validation\n",
    "\n",
    " In k-fold cross-validation, the shuffled training data is partitioned into k disjoint sets and the model is trained on k −1 sets and validated on the kth set. This process is repeated k times with each set chosen as the validation set once. The cross-validation accuracy is reported as the average accuracy of the k iterations\n",
    " \n",
    "__Use 7-fold cross validation on the training data. Print the average accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, train rmse: 0.777778, valid rmse: 0.770115\n",
      "fold 1, train rmse: 0.800766, valid rmse: 0.816092\n",
      "fold 2, train rmse: 0.802682, valid rmse: 0.689655\n",
      "fold 3, train rmse: 0.793103, valid rmse: 0.827586\n",
      "fold 4, train rmse: 0.793103, valid rmse: 0.816092\n",
      "fold 5, train rmse: 0.816092, valid rmse: 0.793103\n",
      "fold 6, train rmse: 0.789272, valid rmse: 0.747126\n",
      "Train RMSE:  0.7961138478379858\n",
      "Valid RMSE:  0.779967159277504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, \n",
    "                                                    random_state=100)\n",
    "\n",
    "from sklearn import linear_model\n",
    "LogisticRegressionModel = linear_model.LogisticRegression()\n",
    "\n",
    "#LogisticRegressionModel.fit(x_train,y_train)\n",
    "\n",
    "#training_accuracy=LogisticRegressionModel.score(x_train,y_train)\n",
    "#print ('training accuracy:',training_accuracy)\n",
    "#test_accuracy=LogisticRegressionModel.score(x_test,y_test)\n",
    "#print('testing accuracy: ',test_accuracy)\n",
    "#print(\"\")\n",
    "\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        y_part = y[idx]\n",
    "        X_part = X[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            #print((y_train))\n",
    "            X_train = X_train.append(X_part)\n",
    "            y_train = y_train.append(y_part)\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def k_fold(k, X_train, y_train):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        LogisticRegressionModel.fit(data[0],data[1])\n",
    "        training_accuracy=LogisticRegressionModel.score(data[0],data[1])\n",
    "        test_accuracy=LogisticRegressionModel.score(data[2],data[3])\n",
    "        print('fold %d, train rmse: %f, valid rmse: %f' % (\n",
    "            i, training_accuracy, test_accuracy))\n",
    "        train_l_sum += training_accuracy\n",
    "        valid_l_sum += test_accuracy\n",
    "    return train_l_sum / k, valid_l_sum / k\n",
    "\n",
    "#k, num_epochs, lr, weight_decay, batch_size = 6, 50, 6, 0, 100\n",
    "train_l, valid_l = k_fold(7, x_train, y_train)\n",
    "\n",
    "print(\"Train RMSE: \", train_l)\n",
    "print(\"Valid RMSE: \", valid_l)\n",
    "\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q2.4__\n",
    "\n",
    "One of the preprocessing steps in Data science is Feature Scaling i.e getting all our data on the same scale by setting same  Min-Max of feature values. \n",
    "This makes training less sensitive to the scale of features . \n",
    "Scaling is important in algorithms that use distance functions as a part of classification. If we Scale features in the range [0,1] it is called unity based normalization.\n",
    "\n",
    "__Perform unity based normalization on the above dataset and train the model again, compare model performance in training and validation with your previous model.__  \n",
    "\n",
    "refer:http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler  \n",
    "more at: https://en.wikipedia.org/wiki/Feature_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, train rmse: 0.818008, valid rmse: 0.839080\n",
      "fold 1, train rmse: 0.839080, valid rmse: 0.873563\n",
      "fold 2, train rmse: 0.844828, valid rmse: 0.735632\n",
      "fold 3, train rmse: 0.852490, valid rmse: 0.827586\n",
      "fold 4, train rmse: 0.837165, valid rmse: 0.850575\n",
      "fold 5, train rmse: 0.858238, valid rmse: 0.816092\n",
      "fold 6, train rmse: 0.840996, valid rmse: 0.816092\n",
      "Train RMSE:  0.841543513957307\n",
      "Valid RMSE:  0.8226600985221675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Derek\\Miniconda3\\envs\\gluon\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "#print(type(x_train))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, \n",
    "                                                    random_state=100)\n",
    "#print(x_train)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "x_train = preprocessing.scale(x_train)\n",
    "\n",
    "x_train = pd.DataFrame(x_train,\n",
    "                    columns=['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8'])\n",
    "#x_train\n",
    "\n",
    "#type(x_train)\n",
    "x_test = preprocessing.scale(x_test)\n",
    "x_test = pd.DataFrame(x_test,\n",
    "                    columns=['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8'])\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "LogisticRegressionModel = linear_model.LogisticRegression()\n",
    "\n",
    "#LogisticRegressionModel.fit(x_train,y_train)\n",
    "\n",
    "#training_accuracy=LogisticRegressionModel.score(x_train,y_train)\n",
    "#print ('training accuracy:',training_accuracy)\n",
    "#test_accuracy=LogisticRegressionModel.score(x_test,y_test)\n",
    "#print('testing accuracy: ',test_accuracy)\n",
    "#print(\"\")\n",
    "\n",
    "\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        y_part = y[idx]\n",
    "        X_part = X[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            #print((X_train))\n",
    "            #X_train = X_train.asnumpy()\n",
    "            X_train = X_train.append(X_part)\n",
    "            y_train = y_train.append(y_part)\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def k_fold(k, X_train, y_train):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        LogisticRegressionModel.fit(data[0],data[1])\n",
    "        training_accuracy=LogisticRegressionModel.score(data[0],data[1])\n",
    "        test_accuracy=LogisticRegressionModel.score(data[2],data[3])\n",
    "        print('fold %d, train rmse: %f, valid rmse: %f' % (\n",
    "            i, training_accuracy, test_accuracy))\n",
    "        train_l_sum += training_accuracy\n",
    "        valid_l_sum += test_accuracy\n",
    "    return train_l_sum / k, valid_l_sum / k\n",
    "\n",
    "#k, num_epochs, lr, weight_decay, batch_size = 6, 50, 6, 0, 100\n",
    "train_l, valid_l = k_fold(7, x_train, y_train)\n",
    "\n",
    "print(\"Train RMSE: \", train_l)\n",
    "print(\"Valid RMSE: \", valid_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
